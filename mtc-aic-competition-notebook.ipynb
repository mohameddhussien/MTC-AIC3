{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mne.decoding import CSP\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from huggingface_hub import hf_hub_download\n",
    "from braindecode.models import EEGNetv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "base_path = './'\n",
    "train_df = pd.read_csv(os.path.join(base_path, 'train.csv'))\n",
    "validation_df = pd.read_csv(os.path.join(base_path, 'validation.csv'))\n",
    "test_df = pd.read_csv(os.path.join(base_path, 'test.csv'))\n",
    "\n",
    "# Function to load a trial's EEG data\n",
    "def load_trial_data(row, base_path='.'):\n",
    "    # Determine dataset type based on ID range\n",
    "    id_num = row['id']\n",
    "    if id_num <= 4800:\n",
    "        dataset = 'train'\n",
    "    elif id_num <= 4900:\n",
    "        dataset = 'validation'\n",
    "    else:\n",
    "        dataset = 'test'\n",
    "\n",
    "    # Construct the path to EEGdata.csv\n",
    "    eeg_path = f\"{base_path}/{row['task']}/{dataset}/{row['subject_id']}/{row['trial_session']}/EEGdata.csv\"\n",
    "\n",
    "    # Load the entire EEG file\n",
    "    eeg_data = pd.read_csv(eeg_path)\n",
    "\n",
    "    # Calculate indices for the specific trial\n",
    "    trial_num = int(row['trial'])\n",
    "    if row['task'] == 'MI':\n",
    "        samples_per_trial = 2250  # 9 seconds * 250 Hz\n",
    "    else:  # SSVEP\n",
    "        samples_per_trial = 1750  # 7 seconds * 250 Hz\n",
    "\n",
    "    start_idx = (trial_num - 1) * samples_per_trial\n",
    "    end_idx = start_idx + samples_per_trial - 1\n",
    "\n",
    "    # Extract the trial data\n",
    "    trial_data = eeg_data.iloc[start_idx:end_idx+1]\n",
    "    return trial_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "EEG_CHANNELS = ['FZ', 'C3', 'CZ', 'C4', 'PZ', 'PO7', 'OZ', 'PO8']\n",
    "SAMPLE_RATE = 250\n",
    "BANDPASS = (8, 30)\n",
    "CROP_WINDOW = (1.5, 7)\n",
    "ica_model = FastICA(random_state=42, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Signal Processing ---\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    b, a = butter(order, [lowcut / nyq, highcut / nyq], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def apply_bandpass(data, lowcut, highcut, fs):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs)\n",
    "    return lfilter(b, a, data, axis=0)\n",
    "\n",
    "# --- ICA Cleaning ---\n",
    "def apply_ica(data, transform_only=False):\n",
    "    ica_model.n_components = data.shape[1]\n",
    "    if transform_only:\n",
    "        transformed = ica_model.transform(data)\n",
    "    else:\n",
    "        transformed = ica_model.fit_transform(data)\n",
    "        \n",
    "    cleaned = ica_model.inverse_transform(transformed)\n",
    "    return cleaned\n",
    "\n",
    "def normalize_for_plot(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return (df - df.mean(axis=0)) / df.std(axis=0)\n",
    "\n",
    "# --- Trial Preprocessing ---\n",
    "def preprocess_trial(trial_df: pd.DataFrame, transform_only=False) -> pd.DataFrame:\n",
    "    # 1. Select EEG channels\n",
    "    eeg = trial_df[EEG_CHANNELS].values\n",
    "\n",
    "    # 2. Bandpass filter\n",
    "    eeg = apply_bandpass(eeg, *BANDPASS, fs=SAMPLE_RATE)\n",
    "\n",
    "    # 3. ICA artifact removal\n",
    "    eeg = apply_ica(eeg, transform_only)\n",
    "\n",
    "    start_idx = CROP_WINDOW[0] * SAMPLE_RATE\n",
    "    end_idx = CROP_WINDOW[1] * SAMPLE_RATE\n",
    "    eeg = eeg[math.floor(start_idx):math.floor(end_idx), :]\n",
    "\n",
    "    # 5. Z-score normalization (per channel)\n",
    "    eeg = normalize_for_plot(eeg)\n",
    "\n",
    "    return eeg.T  # return shape: (n_channels, n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_csp_features(X_list, y_list, n_components=4, for_deep_learning=False):\n",
    "    X = np.array(X_list)  # shape: (n_trials, n_channels, n_samples)\n",
    "    y = np.array(y_list)\n",
    "\n",
    "    if for_deep_learning:\n",
    "        csp = CSP(n_components, transform_into='csp_space')\n",
    "    else:\n",
    "        csp = CSP(n_components, transform_into='average_power', log=True)\n",
    "\n",
    "    X_csp = csp.fit_transform(X, y)\n",
    "    return X_csp, csp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# def compare_eeg_preprocessing(original_df: pd.DataFrame, processed_df: pd.DataFrame, channels=None, sample_rate=250, seconds=5):\n",
    "#     \"\"\"\n",
    "#     Plot original vs preprocessed EEG signals for selected channels and duration.\n",
    "#     \"\"\"\n",
    "#     if channels is None:\n",
    "#         channels = ['C3', 'CZ', 'C4']\n",
    "\n",
    "#     n_samples = sample_rate * seconds\n",
    "#     time = np.arange(n_samples) / sample_rate\n",
    "\n",
    "#     fig, axs = plt.subplots(len(channels), 1, figsize=(12, 2.5 * len(channels)), sharex=True)\n",
    "\n",
    "#     for idx, ch in enumerate(channels):\n",
    "#         axs[idx].plot(time, original_df[ch][:n_samples], label='Original', alpha=0.7)\n",
    "#         axs[idx].plot(time, processed_df[ch][:n_samples], label='Preprocessed', alpha=0.7)\n",
    "#         axs[idx].set_title(f\"Channel: {ch}\")\n",
    "#         axs[idx].legend(loc='upper right')\n",
    "#         axs[idx].set_ylabel('Amplitude (μV)')\n",
    "\n",
    "#     axs[-1].set_xlabel('Time (s)')\n",
    "#     plt.tight_layout()\n",
    "#     plt.suptitle(\"EEG Signal Before vs After Preprocessing\", fontsize=16, y=1.02)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# trial_data = load_trial_data(train_df.iloc[0], base_path)\n",
    "# preprocessed = preprocess_trial(trial_data)\n",
    "# compare_eeg_preprocessing(normalize_for_plot(trial_data), preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def preprocess_data(df, base_path, transform_only=False, test_data=False):\n",
    "    X, y = [], []\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Preprocessing Trials\"):\n",
    "        try:\n",
    "            trial_data = load_trial_data(row, base_path)\n",
    "            processed = preprocess_trial(trial_data, transform_only)\n",
    "            X.append(processed)\n",
    "            if not test_data:\n",
    "                y.append(0 if row[\"label\"] == \"Left\" else 1)\n",
    "        except Exception as e:\n",
    "            print(f\"Trial {idx} skipped due to error: {e}\")\n",
    "    # return np.array(X), np.array(y)\n",
    "    return torch.tensor(np.array(X), dtype=torch.float32), torch.tensor(np.array(y), dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing Trials:  10%|█         | 2/20 [00:00<00:03,  5.17it/s]e:\\Abdo-Projects\\MTC-AIC3\\venv\\Lib\\site-packages\\sklearn\\decomposition\\_fastica.py:127: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  warnings.warn(\n",
      "Preprocessing Trials:  40%|████      | 8/20 [00:03<00:03,  3.52it/s]e:\\Abdo-Projects\\MTC-AIC3\\venv\\Lib\\site-packages\\sklearn\\decomposition\\_fastica.py:127: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  warnings.warn(\n",
      "Preprocessing Trials:  60%|██████    | 12/20 [00:05<00:03,  2.63it/s]e:\\Abdo-Projects\\MTC-AIC3\\venv\\Lib\\site-packages\\sklearn\\decomposition\\_fastica.py:127: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  warnings.warn(\n",
      "Preprocessing Trials:  65%|██████▌   | 13/20 [00:06<00:05,  1.39it/s]e:\\Abdo-Projects\\MTC-AIC3\\venv\\Lib\\site-packages\\sklearn\\decomposition\\_fastica.py:127: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  warnings.warn(\n",
      "Preprocessing Trials:  90%|█████████ | 18/20 [00:09<00:00,  2.29it/s]e:\\Abdo-Projects\\MTC-AIC3\\venv\\Lib\\site-packages\\sklearn\\decomposition\\_fastica.py:127: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
      "  warnings.warn(\n",
      "Preprocessing Trials: 100%|██████████| 20/20 [00:11<00:00,  1.76it/s]\n",
      "Preprocessing Trials: 100%|██████████| 5/5 [00:00<00:00,  6.44it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = preprocess_data(train_df[:20], base_path)\n",
    "X_val, y_val = preprocess_data(validation_df[:5], base_path, transform_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = torch.cat([X_train, X_val], dim=0)\n",
    "y_full = torch.cat([y_train, y_val], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing Trials: 100%|██████████| 50/50 [00:08<00:00,  6.14it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = preprocess_data(test_df[:50], base_path, transform_only=True, test_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Abdo-Projects\\MTC-AIC3\\venv\\Lib\\site-packages\\braindecode\\models\\base.py:23: UserWarning: EEGNetv4: 'in_chans' is depreciated. Use 'n_chans' instead.\n",
      "  warnings.warn(\n",
      "e:\\Abdo-Projects\\MTC-AIC3\\venv\\Lib\\site-packages\\braindecode\\models\\base.py:23: UserWarning: EEGNetv4: 'n_classes' is depreciated. Use 'n_outputs' instead.\n",
      "  warnings.warn(\n",
      "e:\\Abdo-Projects\\MTC-AIC3\\venv\\Lib\\site-packages\\braindecode\\models\\base.py:23: UserWarning: EEGNetv4: 'input_window_samples' is depreciated. Use 'n_times' instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "path = hf_hub_download(repo_id='PierreGtch/EEGNetv4', filename='EEGNetv4_Lee2019_MI/model-params.pkl')\n",
    "module = EEGNetv4(\n",
    "    in_chans=len(EEG_CHANNELS),\n",
    "    input_window_samples=2250,\n",
    "    n_classes=2,\n",
    ").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "module = module.to(device)\n",
    "X_full = X_full.to(device)\n",
    "y_full = y_full.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X_full, y_full)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(module.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Calculated padded input size per channel: (1 x 43). Kernel size: (1 x 70). Kernel size can't be greater than actual input size",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, (inputs, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[32m      6\u001b[39m     optimizer.zero_grad()\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     outputs = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     loss = criterion(outputs, labels)\n\u001b[32m      9\u001b[39m     loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Abdo-Projects\\MTC-AIC3\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Abdo-Projects\\MTC-AIC3\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Abdo-Projects\\MTC-AIC3\\venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Abdo-Projects\\MTC-AIC3\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Abdo-Projects\\MTC-AIC3\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Abdo-Projects\\MTC-AIC3\\venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Abdo-Projects\\MTC-AIC3\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Abdo-Projects\\MTC-AIC3\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Abdo-Projects\\MTC-AIC3\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Abdo-Projects\\MTC-AIC3\\venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    539\u001b[39m         F.pad(\n\u001b[32m    540\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    547\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    548\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Calculated padded input size per channel: (1 x 43). Kernel size: (1 x 70). Kernel size can't be greater than actual input size"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "module.train()\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = module(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(dataloader):.4f}\")\n",
    "\n",
    "torch.save(module.state_dict(), 'eegnet_trained.pth')\n",
    "print(\"Model trained and saved as 'eegnet_trained.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train_csp, csp_model = extract_csp_features(X_train, y_train, n_components=4)\n",
    "X_val_csp = csp_model.transform(X_val)\n",
    "X_test_csp = csp_model.transform(X_test)\n",
    "\n",
    "# print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "# print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# sns.heatmap(\n",
    "#     confusion_matrix(y_test, y_pred),\n",
    "#     annot=True,\n",
    "#     fmt='d',\n",
    "#     cmap='Blues',\n",
    "#     xticklabels=['Left', 'Right'],\n",
    "#     yticklabels=['Left', 'Right']\n",
    "# )\n",
    "# plt.xlabel(\"Predicted\")\n",
    "# plt.ylabel(\"Actual\")\n",
    "# plt.title(\"Confusion Matrix\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def svm_pipeline(X_train, y_train, X_test):\n",
    "    clf_pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', SVC(kernel='rbf', C=1, gamma=0.01))\n",
    "    ])\n",
    "\n",
    "    clf_pipeline.fit(X_train, y_train)\n",
    "    # param_grid = {\n",
    "    #     'classifier__C': [0.1, 1, 10],\n",
    "    #     'classifier__gamma': [0.01, 0.1, 1]\n",
    "    # }\n",
    "\n",
    "    # grid = GridSearchCV(clf_pipeline, param_grid, cv=5)\n",
    "    # grid.fit(X_train, y_train)\n",
    "    return clf_pipeline.predict(X_test)\n",
    "\n",
    "def lda_pipeline(X_train, y_train, X_test):\n",
    "    clf_pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', LDA())\n",
    "    ])\n",
    "    clf_pipeline.fit(X_train, y_train)\n",
    "    return clf_pipeline.predict(X_test)\n",
    "\n",
    "y_pred_svm = svm_pipeline(X_train_csp, y_train, X_val_csp)\n",
    "y_pred_lda = lda_pipeline(X_train_csp, y_train, X_val_csp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_val, y_pred_svm)\n",
    "f1 = f1_score(y_val, y_pred_svm)\n",
    "\n",
    "print(\"Accuracy: \",acc)\n",
    "\n",
    "print(\"F1: \",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# def save_predictions(y_pred: np.ndarray, test_df: pd.DataFrame, filename: str):\n",
    "#     # map y_pred to left or right\n",
    "#     predictions = np.where(y_pred == 0, \"Left\", \"Right\")\n",
    "\n",
    "#     # create a dataframe with the predictions and the actual labels\n",
    "#     predictions_df = pd.DataFrame({\n",
    "#         \"label\": predictions\n",
    "#     })\n",
    "\n",
    "#     predictions_df[\"id\"] = test_df[\"id\"]\n",
    "#     predictions_df = predictions_df[[\"id\", \"label\"]]\n",
    "#     predictions_df.to_csv(f'{filename}_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# save_predictions(y_pred_lda, test_df, \"lda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# save_predictions(y_pred_svm, test_df, \"svm\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12673416,
     "isSourceIdPinned": false,
     "sourceId": 98188,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
