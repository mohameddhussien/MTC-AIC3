{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import butter, lfilter\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mne.decoding import CSP\n",
    "import math\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "base_path = './'\n",
    "train_df = pd.read_csv(os.path.join(base_path, 'train.csv'))\n",
    "validation_df = pd.read_csv(os.path.join(base_path, 'validation.csv'))\n",
    "test_df = pd.read_csv(os.path.join(base_path, 'test.csv'))\n",
    "\n",
    "# Function to load a trial's EEG data\n",
    "def load_trial_data(row, base_path='.'):\n",
    "    # Determine dataset type based on ID range\n",
    "    id_num = row['id']\n",
    "    if id_num <= 4800:\n",
    "        dataset = 'train'\n",
    "    elif id_num <= 4900:\n",
    "        dataset = 'validation'\n",
    "    else:\n",
    "        dataset = 'test'\n",
    "\n",
    "    # Construct the path to EEGdata.csv\n",
    "    eeg_path = f\"{base_path}/{row['task']}/{dataset}/{row['subject_id']}/{row['trial_session']}/EEGdata.csv\"\n",
    "\n",
    "    # Load the entire EEG file\n",
    "    eeg_data = pd.read_csv(eeg_path)\n",
    "\n",
    "    # Calculate indices for the specific trial\n",
    "    trial_num = int(row['trial'])\n",
    "    if row['task'] == 'MI':\n",
    "        samples_per_trial = 2250  # 9 seconds * 250 Hz\n",
    "    else:  # SSVEP\n",
    "        samples_per_trial = 1750  # 7 seconds * 250 Hz\n",
    "\n",
    "    start_idx = (trial_num - 1) * samples_per_trial\n",
    "    end_idx = start_idx + samples_per_trial - 1\n",
    "\n",
    "    # Extract the trial data\n",
    "    trial_data = eeg_data.iloc[start_idx:end_idx+1]\n",
    "    return trial_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "EEG_CHANNELS = ['FZ', 'C3', 'CZ', 'C4', 'PZ', 'PO7', 'OZ', 'PO8']\n",
    "SAMPLE_RATE = 250\n",
    "BANDPASS = (8, 30)\n",
    "CROP_WINDOW = (1.5, 7)\n",
    "ica_model = FastICA(random_state=42, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Signal Processing ---\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    b, a = butter(order, [lowcut / nyq, highcut / nyq], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def apply_bandpass(data, lowcut, highcut, fs):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs)\n",
    "    return lfilter(b, a, data, axis=0)\n",
    "\n",
    "# --- ICA Cleaning ---\n",
    "def apply_ica(data, transform_only=False):\n",
    "    ica_model.n_components = data.shape[1]\n",
    "    if transform_only:\n",
    "        transformed = ica_model.transform(data)\n",
    "    else:\n",
    "        transformed = ica_model.fit_transform(data)\n",
    "        \n",
    "    cleaned = ica_model.inverse_transform(transformed)\n",
    "    return cleaned\n",
    "\n",
    "def normalize_for_plot(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return (df - df.mean(axis=0)) / df.std(axis=0)\n",
    "\n",
    "# --- Trial Preprocessing ---\n",
    "def preprocess_trial(trial_df: pd.DataFrame, transform_only=False) -> pd.DataFrame:\n",
    "    # 1. Select EEG channels\n",
    "    eeg = trial_df[EEG_CHANNELS].values\n",
    "\n",
    "    # 2. Bandpass filter\n",
    "    eeg = apply_bandpass(eeg, *BANDPASS, fs=SAMPLE_RATE)\n",
    "\n",
    "    # 3. ICA artifact removal\n",
    "    eeg = apply_ica(eeg, transform_only)\n",
    "\n",
    "    start_idx = CROP_WINDOW[0] * SAMPLE_RATE\n",
    "    end_idx = CROP_WINDOW[1] * SAMPLE_RATE\n",
    "    eeg = eeg[math.floor(start_idx):math.floor(end_idx), :]\n",
    "\n",
    "    # 5. Z-score normalization (per channel)\n",
    "    eeg = normalize_for_plot(eeg)\n",
    "\n",
    "    return eeg.T  # return shape: (n_channels, n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_csp_features(X_list, y_list, n_components=4, for_deep_learning=False):\n",
    "    X = np.array(X_list)  # shape: (n_trials, n_channels, n_samples)\n",
    "    y = np.array(y_list)\n",
    "\n",
    "    if for_deep_learning:\n",
    "        csp = CSP(n_components, transform_into='csp_space')\n",
    "    else:\n",
    "        csp = CSP(n_components, transform_into='average_power', log=True)\n",
    "\n",
    "    X_csp = csp.fit_transform(X, y)\n",
    "    return X_csp, csp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# def compare_eeg_preprocessing(original_df: pd.DataFrame, processed_df: pd.DataFrame, channels=None, sample_rate=250, seconds=5):\n",
    "#     \"\"\"\n",
    "#     Plot original vs preprocessed EEG signals for selected channels and duration.\n",
    "#     \"\"\"\n",
    "#     if channels is None:\n",
    "#         channels = ['C3', 'CZ', 'C4']\n",
    "\n",
    "#     n_samples = sample_rate * seconds\n",
    "#     time = np.arange(n_samples) / sample_rate\n",
    "\n",
    "#     fig, axs = plt.subplots(len(channels), 1, figsize=(12, 2.5 * len(channels)), sharex=True)\n",
    "\n",
    "#     for idx, ch in enumerate(channels):\n",
    "#         axs[idx].plot(time, original_df[ch][:n_samples], label='Original', alpha=0.7)\n",
    "#         axs[idx].plot(time, processed_df[ch][:n_samples], label='Preprocessed', alpha=0.7)\n",
    "#         axs[idx].set_title(f\"Channel: {ch}\")\n",
    "#         axs[idx].legend(loc='upper right')\n",
    "#         axs[idx].set_ylabel('Amplitude (Î¼V)')\n",
    "\n",
    "#     axs[-1].set_xlabel('Time (s)')\n",
    "#     plt.tight_layout()\n",
    "#     plt.suptitle(\"EEG Signal Before vs After Preprocessing\", fontsize=16, y=1.02)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# trial_data = load_trial_data(train_df.iloc[0], base_path)\n",
    "# preprocessed = preprocess_trial(trial_data)\n",
    "# compare_eeg_preprocessing(normalize_for_plot(trial_data), preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def preprocess_data(df, base_path, transform_only=False, test_data=False):\n",
    "    X, y = [], []\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Preprocessing Trials\"):\n",
    "        try:\n",
    "            trial_data = load_trial_data(row, base_path)\n",
    "            processed = preprocess_trial(trial_data, transform_only)\n",
    "            X.append(processed)\n",
    "            if not test_data:\n",
    "                y.append(0 if row[\"label\"] == \"Left\" else 1)\n",
    "        except Exception as e:\n",
    "            print(f\"Trial {idx} skipped due to error: {e}\")\n",
    "    return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = preprocess_data(train_df[:2400], base_path)\n",
    "X_val, y_val = preprocess_data(validation_df[:50], base_path, transform_only=True)\n",
    "\n",
    "X_full = np.concatenate([X_train, X_val], axis=0)\n",
    "y_full = np.concatenate([y_train, y_val], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_test, y_test = preprocess_data(test_df[:50], base_path, transform_only=True, test_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train_csp, csp_model = extract_csp_features(X_train, y_train, n_components=4)\n",
    "X_val_csp = csp_model.transform(X_val)\n",
    "X_test_csp = csp_model.transform(X_test)\n",
    "\n",
    "# print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "# print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# sns.heatmap(\n",
    "#     confusion_matrix(y_test, y_pred),\n",
    "#     annot=True,\n",
    "#     fmt='d',\n",
    "#     cmap='Blues',\n",
    "#     xticklabels=['Left', 'Right'],\n",
    "#     yticklabels=['Left', 'Right']\n",
    "# )\n",
    "# plt.xlabel(\"Predicted\")\n",
    "# plt.ylabel(\"Actual\")\n",
    "# plt.title(\"Confusion Matrix\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def svm_pipeline(X_train, y_train, X_test):\n",
    "    clf_pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', SVC(kernel='linear', C=1, gamma=0.01))\n",
    "    ])\n",
    "\n",
    "    clf_pipeline.fit(X_train, y_train)\n",
    "    # param_grid = {\n",
    "    #     'classifier__C': [0.1, 1, 10],\n",
    "    #     'classifier__gamma': [0.01, 0.1, 1]\n",
    "    # }\n",
    "\n",
    "    # grid = GridSearchCV(clf_pipeline, param_grid, cv=5)\n",
    "    # grid.fit(X_train, y_train)\n",
    "    return clf_pipeline.predict(X_test)\n",
    "\n",
    "def lda_pipeline(X_train, y_train, X_test):\n",
    "    clf_pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', LDA())\n",
    "    ])\n",
    "    clf_pipeline.fit(X_train, y_train)\n",
    "    return clf_pipeline.predict(X_test)\n",
    "\n",
    "y_pred_svm = svm_pipeline(X_train_csp, y_train, X_test_csp)\n",
    "y_pred_lda = lda_pipeline(X_train_csp, y_train, X_test_csp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def save_predictions(y_pred: np.ndarray, test_df: pd.DataFrame, filename: str):\n",
    "    # map y_pred to left or right\n",
    "    predictions = np.where(y_pred == 0, \"Left\", \"Right\")\n",
    "\n",
    "    # create a dataframe with the predictions and the actual labels\n",
    "    predictions_df = pd.DataFrame({\n",
    "        \"label\": predictions\n",
    "    })\n",
    "\n",
    "    predictions_df[\"id\"] = test_df[\"id\"]\n",
    "    predictions_df = predictions_df[[\"id\", \"label\"]]\n",
    "    predictions_df.to_csv(f'{filename}_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "save_predictions(y_pred_lda, test_df, \"lda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "save_predictions(y_pred_svm, test_df, \"svm\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12673416,
     "sourceId": 98188,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
